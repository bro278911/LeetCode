{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AlexNet.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"YDbAUs3uYEy5","colab":{"base_uri":"https://localhost:8080/","height":222},"outputId":"391fa70c-d45c-4773-d34f-c5b4ea0d2217","executionInfo":{"status":"ok","timestamp":1562482333568,"user_tz":-480,"elapsed":62189,"user":{"displayName":"周渲杭","photoUrl":"https://lh6.googleusercontent.com/-zKwzyarYsJ0/AAAAAAAAAAI/AAAAAAAAAvo/X8qAOHkkxEM/s64/photo.jpg","userId":"12796246632629161431"}}},"source":["\n","# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","# !apt-get update -qq 2>&1 > /dev/null\n","# !apt-get -y install -qq google-drive-ocamlfuse fuse\n","# from google.colab import auth\n","# auth.authenticate_user()\n","# from oauth2client.client import GoogleCredentials\n","# creds = GoogleCredentials.get_application_default()\n","# import getpass\n","# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","# vcode = getpass.getpass()\n","# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","# !mkdir -p drive\n","# !google-drive-ocamlfuse drive"],"execution_count":1,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 130942 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.6-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DD2tqCcm3Tw_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1gEkQhahKZiWt1djkCQWOk6NQBraJoUBJ"},"outputId":"340abca0-00e0-4324-a1df-56408b28527c","executionInfo":{"status":"ok","timestamp":1562482421751,"user_tz":-480,"elapsed":68020,"user":{"displayName":"周渲杭","photoUrl":"https://lh6.googleusercontent.com/-zKwzyarYsJ0/AAAAAAAAAAI/AAAAAAAAAvo/X8qAOHkkxEM/s64/photo.jpg","userId":"12796246632629161431"}}},"source":["!cp drive/images.zip ./\n","!unzip images.zip"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WhHNDXvWYI5R"},"source":[""]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Hr6uu3lMzh0M","colab":{}},"source":["import tensorflow as tf\n","from tensorflow.python.training.moving_averages import assign_moving_average\n","import numpy as np\n","import os\n","import cv2\n","import numpy as np\n","import random as rn\n","import tensorflow as tf\n","import threading\n","import time\n","\n","global n_classes\n","n_classes = 50"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wyEhNlDlzh0P","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"54bd20ed-f2ad-4640-ddd5-d3d85143d72d","executionInfo":{"status":"ok","timestamp":1562484547332,"user_tz":-480,"elapsed":808,"user":{"displayName":"周渲杭","photoUrl":"https://lh6.googleusercontent.com/-zKwzyarYsJ0/AAAAAAAAAAI/AAAAAAAAAvo/X8qAOHkkxEM/s64/photo.jpg","userId":"12796246632629161431"}}},"source":["_weights = {\n","        'wc1': tf.get_variable(\"wc1\", [7, 7, 3, 96], initializer=tf.glorot_uniform_initializer()),\n","        'wc2': tf.get_variable('wc2',[5, 5, 96, 256], initializer=tf.glorot_uniform_initializer()),\n","        'wc3': tf.get_variable('wc3',[3, 3, 256, 384], initializer=tf.glorot_uniform_initializer()),\n","        'wc4': tf.get_variable('wc4',[3, 3, 384, 384], initializer=tf.glorot_uniform_initializer()),\n","        'wc5': tf.get_variable('wc5',[3, 3, 384, 256], initializer=tf.glorot_uniform_initializer()),\n","        'wd2': tf.get_variable('wd2',[4096, 4096], initializer=tf.glorot_uniform_initializer()),\n","        'out': tf.get_variable('out',[4096, n_classes], initializer=tf.glorot_uniform_initializer())\n","    }\n","_biases = {\n","        'bc1': tf.get_variable('bc1',[96], initializer=tf.glorot_uniform_initializer()),\n","        'bc2': tf.get_variable('bc2',[256], initializer=tf.glorot_uniform_initializer()),\n","        'bc3': tf.get_variable('bc3',[384], initializer=tf.glorot_uniform_initializer()),\n","        'bc4': tf.get_variable('bc4',[384], initializer=tf.glorot_uniform_initializer()),\n","        'bc5': tf.get_variable('bc5',[256], initializer=tf.glorot_uniform_initializer()),\n","        'bd2': tf.get_variable('db2',[4096], initializer=tf.glorot_uniform_initializer()),\n","        'out': tf.get_variable('bout',[n_classes], initializer=tf.glorot_uniform_initializer())\n","    }"],"execution_count":4,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0707 07:29:08.249492 140274488117120 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z-Oekfd9zh0Q","colab":{}},"source":["def activation(x,name=\"activation\"):\n","    return tf.nn.relu(x, name=name)\n","    \n","def conv2d(name, l_input, w, b, s, p, scope):\n","    l_input = tf.nn.conv2d(l_input, w, strides=[1,s,s,1], padding=p, name=name)\n","    l_input = activation(l_input+b)\n","    \n","    return l_input\n","\n","def max_pool(name, l_input, k, s):\n","    return tf.nn.max_pool(l_input, ksize=[1, k, k, 1], strides=[1, s, s, 1], padding='VALID', name=name)\n","\n","def norm(l_input, lsize=4, name=\"lrn\"):\n","    return tf.nn.lrn(l_input, lsize, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=name)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"94VSiHqhzh0S","colab":{}},"source":["   \n","def alex_net(_X, _dropout, batch_size):\n","    conv1 = conv2d('conv1', _X, _weights['wc1'], _biases['bc1'], 3, 'VALID', 'conv1')\n","    pool1 = max_pool('pool1', conv1, k=3,s=2)\n","    conv2 = conv2d('conv2', pool1, _weights['wc2'], _biases['bc2'], 1, 'SAME', 'conv2')\n","    pool2 = max_pool('pool2', conv2, k=3,s=2)\n","    conv3 = conv2d('conv3', pool2, _weights['wc3'], _biases['bc3'], 1, 'SAME', 'conv3')\n","    conv4 = conv2d('conv4', conv3, _weights['wc4'], _biases['bc4'], 1, 'SAME', 'conv4')\n","    conv5 = conv2d('conv5', conv4, _weights['wc5'], _biases['bc5'], 1, 'SAME', 'conv5')\n","    pool5 = max_pool('pool2', conv5, k=3,s=2)\n","    # Find current size of conv5 to fit the requirement of FC1.\n","    sizes = pool5.get_shape().as_list()\n","    neurons =  sizes[1]*sizes[2]*sizes[3]\n","    dense1 = tf.reshape(pool5, [batch_size, neurons]) # Reshape conv5 output to fit dense layer input\n","    wei_den1 = tf.get_variable('wd3',[neurons, 4096], initializer=tf.glorot_uniform_initializer())\n","    b_den1 =  tf.get_variable('wd4',[4096], initializer=tf.glorot_uniform_initializer())\n","    \n","    dense1 = activation(tf.matmul(dense1, wei_den1) + b_den1, name='fc1') # Relu activation\n","    dd1=tf.nn.dropout(dense1, _dropout)\n","    dense2 = activation(tf.matmul(dd1, _weights['wd2']) + _biases['bd2'], name='fc2') # Relu activation\n","    out = tf.matmul(dense2, _weights['out']) + _biases['out'] # Relu activation\n","\n","    return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tCNUC9U1zh0U","colab":{}},"source":["#==========================================================================\n","#=============Reading data in multithreading manner========================\n","#==========================================================================\n","def read_labeled_image_list(image_list_file, training_img_dir):\n","    \"\"\"Reads a .txt file containing pathes and labeles\n","    Args:\n","       image_list_file: a .txt file with one /path/to/image per line\n","       label: optionally, if set label will be pasted after each line\n","    Returns:\n","       List with all filenames in file image_list_file\n","    \"\"\"\n","    f = open(image_list_file, 'r')\n","    filenames = []\n","    labels = []\n","\n","    for line in f:\n","        filename, label = line[:-1].split(' ')\n","        filename = training_img_dir+filename\n","        filenames.append(filename)\n","        labels.append(int(label))\n","        \n","    return filenames, labels\n","    \n","    \n","def read_images_from_disk(input_queue, size1=256):\n","    \"\"\"Consumes a single filename and label as a ' '-delimited string.\n","    Args:\n","      filename_and_label_tensor: A scalar string tensor.\n","    Returns:\n","      Two tensors: the decoded image, and the string label.\n","    \"\"\"\n","    label = input_queue[1]\n","    fn=input_queue[0]\n","    file_contents = tf.read_file(input_queue[0])\n","    example = tf.image.decode_jpeg(file_contents, channels=3)\n","    \n","    #example = tf.image.decode_png(file_contents, channels=3, name=\"dataset_image\") # png fo rlfw\n","    example=tf.image.resize_images(example, [size1,size1])\n","    return example, label, fn\n","    \n","def setup_inputs(sess, filenames, training_img_dir, image_size=256, crop_size=224, isTest=False, batch_size=128):\n","    \n","    # Read each image file\n","    image_list, label_list = read_labeled_image_list(filenames, training_img_dir)\n","\n","    images = tf.cast(image_list, tf.string)\n","    labels = tf.cast(label_list, tf.int64)\n","     # Makes an input queue\n","    if isTest is False:\n","        isShuffle = True\n","    else:\n","        isShuffle = False\n","        \n","    input_queue = tf.train.slice_input_producer([images, labels], shuffle=isShuffle)\n","    image, y,fn = read_images_from_disk(input_queue)\n","\n","    channels = 3\n","    image.set_shape([None, None, channels])\n","        \n","    # Crop and other random augmentations\n","    if isTest is False:\n","        image = tf.image.random_flip_left_right(image)\n","        image = tf.image.random_saturation(image, .95, 1.05)\n","        image = tf.image.random_brightness(image, .05)\n","        image = tf.image.random_contrast(image, .95, 1.05)\n","        \n","\n","    image = tf.random_crop(image, [crop_size, crop_size, 3])\n","    image = tf.cast(image, tf.float32)/255.0\n","    \n","    image, y,fn = tf.train.batch([image, y, fn], batch_size=batch_size, capacity=4,name='labels_and_images')\n","\n","    tf.train.start_queue_runners(sess=sess)\n","\n","    return image, y, fn, len(label_list)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h7AtFd4czh0W","colab":{}},"source":["# Training setting\n","batch_size = 128 \n","display_step = 80\n","dropout = 0.5# Dropout rate\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7LCc7xsQzh0Y","outputId":"4caa10d2-9a95-4c96-889c-5637e5aff5a6","colab":{"base_uri":"https://localhost:8080/","height":574},"executionInfo":{"status":"ok","timestamp":1562484565815,"user_tz":-480,"elapsed":4037,"user":{"displayName":"周渲杭","photoUrl":"https://lh6.googleusercontent.com/-zKwzyarYsJ0/AAAAAAAAAAI/AAAAAAAAAvo/X8qAOHkkxEM/s64/photo.jpg","userId":"12796246632629161431"}}},"source":["keep_prob = tf.placeholder(tf.float32)          # Dropout rate to be fed\n","learning_rate = tf.placeholder(tf.float32)      # Learning rate to be fed\n","lr = 1e-3                                   # Learning rate start\n","\n","# Setup the tensorflow...\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True\n","sess = tf.Session(config=config)\n","\n","print(\"Preparing the training & validation data...\")\n","train_data, train_labels, filelist1, glen1 = setup_inputs(sess, \"train.txt\", \"./\", batch_size=batch_size)\n","val_data, val_labels, filelist2, tlen1 = setup_inputs(sess, \"val.txt\", \"./\", batch_size=batch_size)\n","\n","max_iter = glen1*100\n","\n","print(\"Preparing the training model with learning rate = %.5f...\" % (lr))\n","\n","with tf.variable_scope(\"alexnet\", reuse=tf.AUTO_REUSE) as scope:\n","    pred = alex_net(train_data,keep_prob,batch_size)\n","\n","with tf.name_scope('Loss_and_Accuracy'):\n","  cost = tf.losses.sparse_softmax_cross_entropy(labels=train_labels, logits=pred)\n","  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n","  correct_prediction = tf.equal(tf.argmax(pred, 1), train_labels)\n","  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","  top5=tf.reduce_mean(tf.cast(tf.nn.in_top_k(pred, train_labels, 5), tf.float32))\n","  \n","  tf.summary.scalar('Loss', cost)\n","  tf.summary.scalar('Training_Accuracy', accuracy)\n","  tf.summary.scalar('Top-5_accuracy', top5)\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Preparing the training & validation data...\n"],"name":"stdout"},{"output_type":"stream","text":["W0707 07:29:25.471647 140274488117120 deprecation.py:323] From <ipython-input-7-b45acdff6d74>:51: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n","W0707 07:29:25.481492 140274488117120 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:374: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n","W0707 07:29:25.506071 140274488117120 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:320: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n","W0707 07:29:25.508569 140274488117120 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n","W0707 07:29:25.512977 140274488117120 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","W0707 07:29:25.520259 140274488117120 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","W0707 07:29:25.587968 140274488117120 deprecation.py:323] From <ipython-input-7-b45acdff6d74>:68: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n","W0707 07:29:25.599407 140274488117120 deprecation.py:323] From <ipython-input-7-b45acdff6d74>:70: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n"],"name":"stderr"},{"output_type":"stream","text":["Preparing the training model with learning rate = 0.00100...\n"],"name":"stdout"},{"output_type":"stream","text":["W0707 07:29:26.191188 140274488117120 deprecation.py:506] From <ipython-input-6-5f240c5a2da9>:19: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0707 07:29:26.223272 140274488117120 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3CGfQ_Cbzh0c","outputId":"40c5cfc1-cace-40f4-e1b5-19626edb6671","colab":{"base_uri":"https://localhost:8080/","height":521}},"source":["saver = tf.train.Saver()\n","init = tf.global_variables_initializer()\n","sess.run(init)\n","step = 0\n","writer = tf.summary.FileWriter(\"/tmp/log2\", sess.graph)\n","summaries = tf.summary.merge_all()\n","\n","print(\"We are going to train the ImageNet model based on AlexNet!!!\")\n","while (step * batch_size) < max_iter:\n","    epoch1=np.floor((step*batch_size)/glen1)\n","    if (((step*batch_size)%glen1 < batch_size) & (lr==1e-3) & (epoch1 >2)):\n","        lr /= 10\n","\n","    sess.run(optimizer,  feed_dict={keep_prob: dropout, learning_rate: lr})\n","\n","    if (step % 15000==1) & (step>15000):\n","        save_path = saver.save(sess, \"checkpoint/tf_alex_model_iter\" + str(step) + \".ckpt\")\n","        print(\"Model saved in file at iteration %d: %s\" % (step*batch_size,save_path))\n","\n","    if step % display_step == 1:\n","        # calculate the loss\n","        loss, acc, top5acc, summaries_string = sess.run([cost, accuracy, top5, summaries], feed_dict={keep_prob: 1.})\n","        print(\"Iter=%d/epoch=%d, Loss=%.6f, Training Accuracy=%.6f, Top-5 Accuracy=%.6f, lr=%f\" % (step*batch_size, epoch1 ,loss, acc, top5acc, lr))\n","        writer.add_summary(summaries_string, step)\n","\n","\n","    step += 1\n","print(\"Optimization Finished!\")\n","save_path = saver.save(sess, \"checkpoint/tf_alex_model.ckpt\")\n","print(\"Model saved in file: %s\" % save_path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["We are going to train the ImageNet model based on AlexNet!!!\n","Iter=128/epoch=0, Loss=4.373519, Training Accuracy=0.031250, Top-5 Accuracy=0.109375, lr=0.001000\n","Iter=10368/epoch=0, Loss=3.783888, Training Accuracy=0.046875, Top-5 Accuracy=0.171875, lr=0.001000\n","Iter=20608/epoch=0, Loss=3.743589, Training Accuracy=0.039062, Top-5 Accuracy=0.179688, lr=0.001000\n","Iter=30848/epoch=0, Loss=3.631274, Training Accuracy=0.070312, Top-5 Accuracy=0.281250, lr=0.001000\n","Iter=41088/epoch=0, Loss=3.827258, Training Accuracy=0.046875, Top-5 Accuracy=0.203125, lr=0.001000\n","Iter=51328/epoch=0, Loss=3.474900, Training Accuracy=0.078125, Top-5 Accuracy=0.351562, lr=0.001000\n","Iter=61568/epoch=0, Loss=3.553555, Training Accuracy=0.117188, Top-5 Accuracy=0.289062, lr=0.001000\n","Iter=71808/epoch=1, Loss=3.485741, Training Accuracy=0.093750, Top-5 Accuracy=0.304688, lr=0.001000\n","Iter=82048/epoch=1, Loss=3.713009, Training Accuracy=0.078125, Top-5 Accuracy=0.250000, lr=0.001000\n","Iter=92288/epoch=1, Loss=3.462412, Training Accuracy=0.101562, Top-5 Accuracy=0.328125, lr=0.001000\n","Iter=102528/epoch=1, Loss=3.583146, Training Accuracy=0.093750, Top-5 Accuracy=0.289062, lr=0.001000\n","Iter=112768/epoch=1, Loss=3.279981, Training Accuracy=0.093750, Top-5 Accuracy=0.421875, lr=0.001000\n","Iter=123008/epoch=1, Loss=3.277013, Training Accuracy=0.125000, Top-5 Accuracy=0.414062, lr=0.001000\n","Iter=133248/epoch=2, Loss=3.310231, Training Accuracy=0.109375, Top-5 Accuracy=0.382812, lr=0.001000\n","Iter=143488/epoch=2, Loss=3.156611, Training Accuracy=0.109375, Top-5 Accuracy=0.414062, lr=0.001000\n","Iter=153728/epoch=2, Loss=2.862270, Training Accuracy=0.210938, Top-5 Accuracy=0.531250, lr=0.001000\n","Iter=163968/epoch=2, Loss=2.875627, Training Accuracy=0.125000, Top-5 Accuracy=0.554688, lr=0.001000\n","Iter=174208/epoch=2, Loss=2.951592, Training Accuracy=0.210938, Top-5 Accuracy=0.515625, lr=0.001000\n","Iter=184448/epoch=2, Loss=3.028154, Training Accuracy=0.164062, Top-5 Accuracy=0.468750, lr=0.001000\n","Iter=194688/epoch=3, Loss=2.921536, Training Accuracy=0.156250, Top-5 Accuracy=0.507812, lr=0.000100\n","Iter=204928/epoch=3, Loss=2.969308, Training Accuracy=0.164062, Top-5 Accuracy=0.523438, lr=0.000100\n","Iter=215168/epoch=3, Loss=2.680192, Training Accuracy=0.296875, Top-5 Accuracy=0.625000, lr=0.000100\n","Iter=225408/epoch=3, Loss=2.746267, Training Accuracy=0.242188, Top-5 Accuracy=0.609375, lr=0.000100\n","Iter=235648/epoch=3, Loss=2.810063, Training Accuracy=0.171875, Top-5 Accuracy=0.593750, lr=0.000100\n","Iter=245888/epoch=3, Loss=2.804431, Training Accuracy=0.234375, Top-5 Accuracy=0.609375, lr=0.000100\n","Iter=256128/epoch=4, Loss=2.922457, Training Accuracy=0.140625, Top-5 Accuracy=0.531250, lr=0.000100\n","Iter=266368/epoch=4, Loss=2.692306, Training Accuracy=0.242188, Top-5 Accuracy=0.578125, lr=0.000100\n","Iter=276608/epoch=4, Loss=2.646342, Training Accuracy=0.265625, Top-5 Accuracy=0.601562, lr=0.000100\n","Iter=286848/epoch=4, Loss=2.660291, Training Accuracy=0.296875, Top-5 Accuracy=0.625000, lr=0.000100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jtfg_YheLPwF","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AOQOeejKzh0f","colab":{}},"source":["exit()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sr0obIo2zh0g","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}